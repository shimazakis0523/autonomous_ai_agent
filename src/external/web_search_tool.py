#!/usr/bin/env python3
"""
Webæ¤œç´¢ãƒ„ãƒ¼ãƒ«ï¼ˆSerpAPIä½¿ç”¨ï¼‰
è©³ç´°ãªãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°æ©Ÿèƒ½ä»˜ã
"""
import os
import json
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
from serpapi import GoogleSearch
from dotenv import load_dotenv

# ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°æ©Ÿèƒ½ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from ..utils.trace_logger import TraceLogger

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

logger = logging.getLogger(__name__)

class WebSearchTool:
    """Webæ¤œç´¢ãƒ„ãƒ¼ãƒ«ï¼ˆãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°å¯¾å¿œï¼‰"""
    
    def __init__(self, trace_logger: Optional[TraceLogger] = None):
        """
        åˆæœŸåŒ–
        
        Args:
            trace_logger: ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ãƒ­ã‚¬ãƒ¼
        """
        self.api_key = os.getenv("SERPAPI_API_KEY")
        self.trace_logger = trace_logger
        
        if not self.api_key:
            logger.warning("SERPAPI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Webæ¤œç´¢æ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
    
    def search_web(self, query: str, num_results: int = 10, language: str = "ja", 
                   country: str = "jp", advanced_params: Optional[Dict] = None) -> Dict[str, Any]:
        """
        Webæ¤œç´¢ã‚’å®Ÿè¡Œ
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            num_results: å–å¾—ã™ã‚‹çµæœæ•°
            language: æ¤œç´¢è¨€èª
            country: æ¤œç´¢å¯¾è±¡å›½
            advanced_params: è¿½åŠ ã®æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            
        Returns:
            æ¤œç´¢çµæœã®è¾æ›¸
        """
        if not self.api_key:
            error_result = {
                "error": "SERPAPI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“",
                "status": "error",
                "results": []
            }
            if self.trace_logger:
                self.trace_logger.log_custom_event(
                    "WEB_SEARCH_ERROR", 
                    "API key not configured", 
                    {"query": query, "error": "Missing API key"}
                )
            return error_result
        
        # æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ§‹ç¯‰
        search_params = {
            "q": query,
            "hl": language,
            "gl": country,
            "num": num_results,
            "api_key": self.api_key
        }
        
        # è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯çµ±åˆ
        if advanced_params:
            search_params.update(advanced_params)
        
        # ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°é–‹å§‹
        if self.trace_logger:
            with self.trace_logger.trace_web_search(query, "Google (SerpAPI)", search_params):
                return self._execute_search(search_params, query)
        else:
            return self._execute_search(search_params, query)
    
    def _execute_search(self, search_params: Dict[str, Any], query: str) -> Dict[str, Any]:
        """
        å®Ÿéš›ã®æ¤œç´¢å®Ÿè¡Œ
        
        Args:
            search_params: æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            
        Returns:
            æ¤œç´¢çµæœ
        """
        try:
            logger.info(f"ğŸ” Webæ¤œç´¢å®Ÿè¡Œ: '{query}'")
            
            # SerpAPIæ¤œç´¢å®Ÿè¡Œ
            search = GoogleSearch(search_params)
            raw_results = search.get_dict()
            
            # çµæœã®æ•´ç†
            processed_results = self._process_search_results(raw_results, query)
            
            # ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ãƒ­ã‚¬ãƒ¼ã«çµæœã‚’è¨˜éŒ²
            if self.trace_logger:
                for result in processed_results.get("results", []):
                    self.trace_logger.log_search_result(result)
            
            logger.info(f"âœ… Webæ¤œç´¢å®Œäº†: {len(processed_results.get('results', []))}ä»¶ã®çµæœã‚’å–å¾—")
            
            return processed_results
            
        except Exception as e:
            error_msg = f"Webæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            
            error_result = {
                "error": error_msg,
                "status": "error",
                "results": [],
                "query": query,
                "timestamp": datetime.now().isoformat()
            }
            
            if self.trace_logger:
                self.trace_logger.log_custom_event(
                    "WEB_SEARCH_ERROR", 
                    error_msg, 
                    {"query": query, "search_params": search_params}
                )
            
            return error_result
    
    def _process_search_results(self, raw_results: Dict, query: str) -> Dict[str, Any]:
        """
        æ¤œç´¢çµæœã®å‡¦ç†ã¨æ•´ç†
        
        Args:
            raw_results: SerpAPIã‹ã‚‰ã®ç”Ÿã®çµæœ
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            
        Returns:
            å‡¦ç†æ¸ˆã¿æ¤œç´¢çµæœ
        """
        processed = {
            "query": query,
            "status": "success",
            "timestamp": datetime.now().isoformat(),
            "results": [],
            "metadata": {},
            "search_info": {},
            "related_searches": []
        }
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®åé›†
        if "search_metadata" in raw_results:
            search_metadata = raw_results["search_metadata"]
            processed["metadata"] = {
                "search_id": search_metadata.get("id", ""),
                "processed_at": search_metadata.get("processed_at", ""),
                "total_time_taken": search_metadata.get("total_time_taken", 0),
                "engine_used": search_metadata.get("engine", "google")
            }
        
        # æ¤œç´¢æƒ…å ±
        if "search_information" in raw_results:
            search_info = raw_results["search_information"]
            processed["search_info"] = {
                "total_results": search_info.get("total_results", "ä¸æ˜"),
                "time_taken": search_info.get("time_taken_displayed", "ä¸æ˜"),
                "query_displayed": search_info.get("query_displayed", query)
            }
        
        # ã‚ªãƒ¼ã‚¬ãƒ‹ãƒƒã‚¯æ¤œç´¢çµæœã®å‡¦ç†
        organic_results = raw_results.get("organic_results", [])
        for i, result in enumerate(organic_results, 1):
            processed_result = {
                "position": result.get("position", i),
                "title": result.get("title", "ã‚¿ã‚¤ãƒˆãƒ«ãªã—"),
                "link": result.get("link", ""),
                "displayed_link": result.get("displayed_link", ""),
                "snippet": result.get("snippet", ""),
                "date": result.get("date", ""),
                "cached_page_link": result.get("cached_page_link", ""),
                "related_pages_link": result.get("related_pages_link", ""),
                "source": "organic"
            }
            
            # ãƒªãƒƒãƒã‚¹ãƒ‹ãƒšãƒƒãƒˆæƒ…å ±ãŒã‚ã‚Œã°è¿½åŠ 
            if "rich_snippet" in result:
                processed_result["rich_snippet"] = result["rich_snippet"]
            
            # ã‚µã‚¤ãƒˆãƒªãƒ³ã‚¯ãŒã‚ã‚Œã°è¿½åŠ 
            if "sitelinks" in result:
                processed_result["sitelinks"] = result["sitelinks"]
            
            processed["results"].append(processed_result)
        
        # ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã®å‡¦ç†
        if "knowledge_graph" in raw_results:
            kg = raw_results["knowledge_graph"]
            knowledge_result = {
                "position": 0,  # ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã¯æœ€ä¸Šä½
                "title": kg.get("title", ""),
                "type": kg.get("type", ""),
                "description": kg.get("description", ""),
                "source": "knowledge_graph",
                "source_link": kg.get("source", {}).get("link", ""),
                "thumbnail": kg.get("thumbnail", "")
            }
            
            # è©³ç´°æƒ…å ±ãŒã‚ã‚Œã°è¿½åŠ 
            if "attributes" in kg:
                knowledge_result["attributes"] = kg["attributes"]
            
            # ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã‚’çµæœã®å…ˆé ­ã«æŒ¿å…¥
            processed["results"].insert(0, knowledge_result)
        
        # ãƒ‹ãƒ¥ãƒ¼ã‚¹çµæœã®å‡¦ç†
        if "news_results" in raw_results:
            news_results = raw_results["news_results"]
            for news in news_results[:3]:  # ä¸Šä½3ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹
                news_result = {
                    "title": news.get("title", ""),
                    "link": news.get("link", ""),
                    "snippet": news.get("snippet", ""),
                    "date": news.get("date", ""),
                    "source": "news",
                    "news_source": news.get("source", "")
                }
                if news.get("thumbnail"):
                    news_result["thumbnail"] = news["thumbnail"]
                
                processed["results"].append(news_result)
        
        # é–¢é€£æ¤œç´¢ã®å‡¦ç†
        if "related_searches" in raw_results:
            related_searches = raw_results["related_searches"]
            processed["related_searches"] = [
                {
                    "query": related.get("query", ""),
                    "link": related.get("link", "")
                }
                for related in related_searches[:5]  # ä¸Šä½5ä»¶
            ]
        
        # çµæœæ•°ã®æ›´æ–°
        processed["results_count"] = len(processed["results"])
        
        # è©³ç´°ãƒ­ã‚°å‡ºåŠ›
        logger.info(f"ğŸ“Š æ¤œç´¢çµæœè©³ç´°:")
        logger.info(f"   â€¢ ã‚ªãƒ¼ã‚¬ãƒ‹ãƒƒã‚¯çµæœ: {len(organic_results)}ä»¶")
        logger.info(f"   â€¢ ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•: {'ã‚ã‚Š' if 'knowledge_graph' in raw_results else 'ãªã—'}")
        logger.info(f"   â€¢ ãƒ‹ãƒ¥ãƒ¼ã‚¹çµæœ: {len(raw_results.get('news_results', []))}ä»¶")
        logger.info(f"   â€¢ é–¢é€£æ¤œç´¢: {len(processed['related_searches'])}ä»¶")
        logger.info(f"   â€¢ ç·çµæœæ•°: {processed['results_count']}ä»¶")
        
        if processed["search_info"].get("total_results"):
            logger.info(f"   â€¢ å…¨ä½“ã®æ¤œç´¢çµæœæ•°: {processed['search_info']['total_results']}")
        
        return processed
    
    def search_images(self, query: str, num_results: int = 10) -> Dict[str, Any]:
        """
        ç”»åƒæ¤œç´¢ã‚’å®Ÿè¡Œ
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            num_results: å–å¾—ã™ã‚‹çµæœæ•°
            
        Returns:
            ç”»åƒæ¤œç´¢çµæœ
        """
        if not self.api_key:
            return {
                "error": "SERPAPI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“",
                "status": "error",
                "results": []
            }
        
        search_params = {
            "q": query,
            "tbm": "isch",  # ç”»åƒæ¤œç´¢
            "num": num_results,
            "api_key": self.api_key
        }
        
        if self.trace_logger:
            with self.trace_logger.trace_web_search(query, "Google Images (SerpAPI)", search_params):
                return self._execute_image_search(search_params, query)
        else:
            return self._execute_image_search(search_params, query)
    
    def _execute_image_search(self, search_params: Dict[str, Any], query: str) -> Dict[str, Any]:
        """ç”»åƒæ¤œç´¢ã®å®Ÿè¡Œ"""
        try:
            logger.info(f"ğŸ–¼ï¸ ç”»åƒæ¤œç´¢å®Ÿè¡Œ: '{query}'")
            
            search = GoogleSearch(search_params)
            raw_results = search.get_dict()
            
            processed_results = {
                "query": query,
                "status": "success",
                "timestamp": datetime.now().isoformat(),
                "results": [],
                "type": "images"
            }
            
            # ç”»åƒçµæœã®å‡¦ç†
            images_results = raw_results.get("images_results", [])
            for i, image in enumerate(images_results, 1):
                image_result = {
                    "position": i,
                    "title": image.get("title", ""),
                    "link": image.get("link", ""),
                    "original": image.get("original", ""),
                    "thumbnail": image.get("thumbnail", ""),
                    "source": image.get("source", ""),
                    "source_logo": image.get("source_logo", "")
                }
                processed_results["results"].append(image_result)
                
                # ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã«è¨˜éŒ²
                if self.trace_logger:
                    self.trace_logger.log_search_result(image_result)
            
            processed_results["results_count"] = len(processed_results["results"])
            logger.info(f"âœ… ç”»åƒæ¤œç´¢å®Œäº†: {processed_results['results_count']}ä»¶ã®ç”»åƒã‚’å–å¾—")
            
            return processed_results
            
        except Exception as e:
            error_msg = f"ç”»åƒæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return {
                "error": error_msg,
                "status": "error",
                "results": [],
                "query": query,
                "timestamp": datetime.now().isoformat()
            }
    
    def search_news(self, query: str, num_results: int = 10, time_range: str = "d") -> Dict[str, Any]:
        """
        ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢ã‚’å®Ÿè¡Œ
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            num_results: å–å¾—ã™ã‚‹çµæœæ•°
            time_range: æ™‚é–“ç¯„å›²ï¼ˆd=1æ—¥ã€w=1é€±é–“ã€m=1ãƒ¶æœˆã€y=1å¹´ï¼‰
            
        Returns:
            ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢çµæœ
        """
        if not self.api_key:
            return {
                "error": "SERPAPI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“",
                "status": "error",
                "results": []
            }
        
        search_params = {
            "q": query,
            "tbm": "nws",  # ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢
            "num": num_results,
            "tbs": f"qdr:{time_range}",  # æ™‚é–“ç¯„å›²
            "api_key": self.api_key
        }
        
        if self.trace_logger:
            with self.trace_logger.trace_web_search(query, "Google News (SerpAPI)", search_params):
                return self._execute_news_search(search_params, query)
        else:
            return self._execute_news_search(search_params, query)
    
    def _execute_news_search(self, search_params: Dict[str, Any], query: str) -> Dict[str, Any]:
        """ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢ã®å®Ÿè¡Œ"""
        try:
            logger.info(f"ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢å®Ÿè¡Œ: '{query}'")
            
            search = GoogleSearch(search_params)
            raw_results = search.get_dict()
            
            processed_results = {
                "query": query,
                "status": "success",
                "timestamp": datetime.now().isoformat(),
                "results": [],
                "type": "news"
            }
            
            # ãƒ‹ãƒ¥ãƒ¼ã‚¹çµæœã®å‡¦ç†
            news_results = raw_results.get("news_results", [])
            for i, news in enumerate(news_results, 1):
                news_result = {
                    "position": i,
                    "title": news.get("title", ""),
                    "link": news.get("link", ""),
                    "snippet": news.get("snippet", ""),
                    "date": news.get("date", ""),
                    "source": news.get("source", ""),
                    "thumbnail": news.get("thumbnail", "")
                }
                processed_results["results"].append(news_result)
                
                # ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã«è¨˜éŒ²
                if self.trace_logger:
                    self.trace_logger.log_search_result(news_result)
            
            processed_results["results_count"] = len(processed_results["results"])
            logger.info(f"âœ… ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢å®Œäº†: {processed_results['results_count']}ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—")
            
            return processed_results
            
        except Exception as e:
            error_msg = f"ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}"
            logger.error(error_msg)
            return {
                "error": error_msg,
                "status": "error",
                "results": [],
                "query": query,
                "timestamp": datetime.now().isoformat()
            } 